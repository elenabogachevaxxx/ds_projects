{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0dVfrCzPWIa"
      },
      "source": [
        "# Проект классификации отзывов для интернет-магазина"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Ybc2CXPWIb"
      },
      "source": [
        " Магазину требуется инструмент, который будет искать токсичные комментарии, оставляемые пользователями в описании товаров магазина и отправлять их на модерацию.\n",
        "\n",
        "**Цель проекта:** Обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Целевое значение метрики качества *F1* не меньше 0.75.\n",
        "\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvq4-MZTPWIb"
      },
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w291FJJyPWIb"
      },
      "outputs": [],
      "source": [
        "!pip install spacy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "harkOhc1PWIc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split,  GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IovIdhrzPWIc"
      },
      "outputs": [],
      "source": [
        "df_comm = pd.read_csv(\"/datasets/toxic_comments.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJlYuxkXPWId"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE=12345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-3LpKS6PWId",
        "outputId": "c37b8d89-5880-4c22-ff4d-51f5852b052e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1           1  D'aww! He matches this background colour I'm s...      0\n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4           4  You, sir, are my hero. Any chance you remember...      0\n",
              "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
              "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
              "7           7  Your vandalism to the Matt Shirvington article...      0\n",
              "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
              "9           9  alignment on this subject and which are contra...      0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comm.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IuS1YQWPWIe",
        "outputId": "dc8ae137-5fd0-4cf8-cf7e-e9d021a433a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159292 entries, 0 to 159291\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  159292 non-null  int64 \n",
            " 1   text        159292 non-null  object\n",
            " 2   toxic       159292 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 3.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df_comm.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5Ps6WgWPWIe",
        "outputId": "d0b23ac2-d5ec-4462-ac92-75632975b8dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comm.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IC5FMO-PWIe",
        "outputId": "f4a49643-24ac-4dd1-b81e-eeff71e7c7c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "text          0\n",
              "toxic         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comm.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvyWLOnuPWIe"
      },
      "source": [
        "Датасет состоит из 159292 строк, столбца с текстами сообщений и стобца с разметкой целевого признака. Пропусков и дубликатов в датасете нет. Посмотрим на соотношение классов целевого признака"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9UYDBrePWIf",
        "outputId": "30ebe697-6bf5-4a41-e5a0-3c608c186422"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    143106\n",
              "1     16186\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comm['toxic'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rf63uwzPWIf"
      },
      "source": [
        "Имеет место выраженный дисбаланс целевого признака (нетоксичных комментариев почти в 10 раз больше чем токсичных), однако менять датасет не будем чтобы получить более честную работу моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3M6AD6pPWIf"
      },
      "source": [
        " Для подготовки данных к обучению удалим лишние символы и пробелы с помощью регулярных выражений, токенизируем и лемматизируем текст. Очищенный текст добавим в датасет. Для удобства выполним подготовку с помощью функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d8b7cec5eaee437680dc730374e1455f"
          ]
        },
        "id": "AXlkSgVfPWIg",
        "outputId": "a466923e-7894-41fa-c9f4-d6bfb1afe6ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8b7cec5eaee437680dc730374e1455f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/159292 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    regular = r'[\\*+\\#+\\№\\\"\\-+\\+\\=+\\?+\\&\\^\\.+\\;\\,+\\>+\\(\\)\\/+\\:\\\\+]'\n",
        "    regular_url = r'(http\\S+)|(www\\S+)|([\\w\\d]+www\\S+)|([\\w\\d]+http\\S+)'\n",
        "    text = re.sub(regular, '', text)\n",
        "    text = re.sub(r'(\\d+\\s\\d+)|(\\d+)',' NUM ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "def lemmatize_text(text):\n",
        "    text = clean_text(text)\n",
        "    doc = nlp(text)\n",
        "    text = [token.lemma_ for token in doc]\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "tqdm.pandas()\n",
        "df_comm['lemm_text'] = df_comm['text'].progress_apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zwe7SVhCPWIg",
        "outputId": "041a6692-e7b7-4aac-ea94-ab33b85b7180"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation why the edit make under my usernam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>d'aww ! he match this background colour I be s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man I be really not try to edit war it be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>more I can not make any real suggestion on i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir be my hero any chance you remember wha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic  \\\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1           1  D'aww! He matches this background colour I'm s...      0   \n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \n",
              "0  explanation why the edit make under my usernam...  \n",
              "1  d'aww ! he match this background colour I be s...  \n",
              "2  hey man I be really not try to edit war it be ...  \n",
              "3    more I can not make any real suggestion on i...  \n",
              "4  you sir be my hero any chance you remember wha...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_comm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIwdvL6pPWIg"
      },
      "source": [
        " Следующим этапом выделим признаки, на которых будем обучать модели. Разделим датасет на тренировочную и тествовую выборки, при разделении учтем дисбаланс классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2glqVtpjPWIh"
      },
      "outputs": [],
      "source": [
        "X=df_comm['lemm_text']\n",
        "y=df_comm['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErK1hL9ePWIh"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, stratify=y, random_state=12345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyZ6YSO1PWIh"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKKVzA8zPWIh"
      },
      "source": [
        "для обучения моделей используем пайплайн с классификаторами - дерево решений, логистическая регрессия, KNN. Проведем кросс-валидацию для подбора гиперпараметров моделей. Результаты обучения всех моделей выведем в таблицу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37WYDTdNPWIi"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([\n",
        "    ('vect', TfidfVectorizer()),\n",
        "    ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyocNDU8PWIi"
      },
      "outputs": [],
      "source": [
        "param_grid = [\n",
        "    {\n",
        "    \"vect__ngram_range\": ((1, 1), (1, 2))\n",
        "    },\n",
        "    {\n",
        "        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
        "        'models__min_samples_leaf': range(3,6),\n",
        "        'models__max_depth': range(3,6)\n",
        "    },\n",
        "    {\n",
        "        'models': [LogisticRegression(random_state=RANDOM_STATE)],\n",
        "        'models__C': range(5,15),\n",
        "        'models__penalty': ['l1', 'l2', 'elasticnet']\n",
        "    } ,\n",
        "    {\n",
        "        'models': [KNeighborsClassifier(n_neighbors=300)]\n",
        "\n",
        "    }\n",
        "                 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQOpr8pTPWIi"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(\n",
        "    pipe,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8D8vn4BhPWIi",
        "outputId": "70ca75be-26d8-47d6-e561-43078b8d9bf7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
            "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.69157891 0.6793398  0.42772078 0.42796632 0.42815329 0.47222048\n",
            " 0.47228342 0.4735418  0.50285623 0.50266596 0.50279531        nan\n",
            " 0.77197468        nan        nan 0.77449296        nan        nan\n",
            " 0.77687744        nan        nan 0.7776455         nan        nan\n",
            " 0.77966198        nan        nan 0.77965918        nan        nan\n",
            " 0.78060949        nan        nan 0.78076077        nan        nan\n",
            " 0.78129203        nan        nan 0.78122135        nan 0.45295919]\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
              "                                       ('models',\n",
              "                                        DecisionTreeClassifier(random_state=12345))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'vect__ngram_range': ((1, 1), (1, 2))},\n",
              "                         {'models': [DecisionTreeClassifier(random_state=12345)],\n",
              "                          'models__max_depth': range(3, 6),\n",
              "                          'models__min_samples_leaf': range(3, 6)},\n",
              "                         {'models': [LogisticRegression(C=13,\n",
              "                                                        random_state=12345)],\n",
              "                          'models__C': range(5, 15),\n",
              "                          'models__penalty': ['l1', 'l2', 'elasticnet']},\n",
              "                         {'models': [KNeighborsClassifier(n_neighbors=300)]}],\n",
              "             scoring='f1')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD0Aivo9PWIk",
        "outputId": "342bafb9-46f3-4da2-d378-5176bfdc9894"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>param_vect__ngram_range</th>\n",
              "      <th>param_models</th>\n",
              "      <th>param_models__max_depth</th>\n",
              "      <th>param_models__min_samples_leaf</th>\n",
              "      <th>param_models__C</th>\n",
              "      <th>param_models__penalty</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133.197824</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.691579</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>604.631311</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.679340</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.764830</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.427721</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.720769</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.427966</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.699417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.428153</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.151276</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.472220</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.111781</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.472283</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.119505</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.473542</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.577193</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.502856</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.585274</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.502666</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.579880</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DecisionTreeClassifier(random_state=12345)</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.502795</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.504694</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>44.562241</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.771975</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.352815</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.470248</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>45.621843</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.774493</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.474125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.407991</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>44.688836</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.776877</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.445324</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.570621</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>44.466175</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.777646</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.450670</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3.397793</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>45.913049</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.779662</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.461948</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3.540653</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>45.443283</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.779659</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.505873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3.486854</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>44.525688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.780609</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3.392231</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3.472540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>44.616034</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.780761</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3.486259</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>3.447714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>45.851809</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.781292</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3.441326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3.433419</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>45.048609</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.781221</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3.419187</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LogisticRegression(C=13, random_state=12345)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>3.420741</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNeighborsClassifier(n_neighbors=300)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.452959</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time param_vect__ngram_range  \\\n",
              "0      133.197824                  (1, 1)   \n",
              "1      604.631311                  (1, 2)   \n",
              "2        4.764830                     NaN   \n",
              "3        4.720769                     NaN   \n",
              "4        4.699417                     NaN   \n",
              "5        5.151276                     NaN   \n",
              "6        5.111781                     NaN   \n",
              "7        5.119505                     NaN   \n",
              "8        5.577193                     NaN   \n",
              "9        5.585274                     NaN   \n",
              "10       5.579880                     NaN   \n",
              "11       3.504694                     NaN   \n",
              "12      44.562241                     NaN   \n",
              "13       3.352815                     NaN   \n",
              "14       3.470248                     NaN   \n",
              "15      45.621843                     NaN   \n",
              "16       3.474125                     NaN   \n",
              "17       3.407991                     NaN   \n",
              "18      44.688836                     NaN   \n",
              "19       3.445324                     NaN   \n",
              "20       3.570621                     NaN   \n",
              "21      44.466175                     NaN   \n",
              "22       3.450670                     NaN   \n",
              "23       3.397793                     NaN   \n",
              "24      45.913049                     NaN   \n",
              "25       3.461948                     NaN   \n",
              "26       3.540653                     NaN   \n",
              "27      45.443283                     NaN   \n",
              "28       3.505873                     NaN   \n",
              "29       3.486854                     NaN   \n",
              "30      44.525688                     NaN   \n",
              "31       3.392231                     NaN   \n",
              "32       3.472540                     NaN   \n",
              "33      44.616034                     NaN   \n",
              "34       3.486259                     NaN   \n",
              "35       3.447714                     NaN   \n",
              "36      45.851809                     NaN   \n",
              "37       3.441326                     NaN   \n",
              "38       3.433419                     NaN   \n",
              "39      45.048609                     NaN   \n",
              "40       3.419187                     NaN   \n",
              "41       3.420741                     NaN   \n",
              "\n",
              "                                    param_models param_models__max_depth  \\\n",
              "0                                            NaN                     NaN   \n",
              "1                                            NaN                     NaN   \n",
              "2     DecisionTreeClassifier(random_state=12345)                       3   \n",
              "3     DecisionTreeClassifier(random_state=12345)                       3   \n",
              "4     DecisionTreeClassifier(random_state=12345)                       3   \n",
              "5     DecisionTreeClassifier(random_state=12345)                       4   \n",
              "6     DecisionTreeClassifier(random_state=12345)                       4   \n",
              "7     DecisionTreeClassifier(random_state=12345)                       4   \n",
              "8     DecisionTreeClassifier(random_state=12345)                       5   \n",
              "9     DecisionTreeClassifier(random_state=12345)                       5   \n",
              "10    DecisionTreeClassifier(random_state=12345)                       5   \n",
              "11  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "12  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "13  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "14  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "15  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "16  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "17  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "18  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "19  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "20  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "21  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "22  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "23  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "24  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "25  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "26  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "27  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "28  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "29  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "30  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "31  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "32  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "33  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "34  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "35  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "36  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "37  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "38  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "39  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "40  LogisticRegression(C=13, random_state=12345)                     NaN   \n",
              "41         KNeighborsClassifier(n_neighbors=300)                     NaN   \n",
              "\n",
              "   param_models__min_samples_leaf param_models__C param_models__penalty  \\\n",
              "0                             NaN             NaN                   NaN   \n",
              "1                             NaN             NaN                   NaN   \n",
              "2                               3             NaN                   NaN   \n",
              "3                               4             NaN                   NaN   \n",
              "4                               5             NaN                   NaN   \n",
              "5                               3             NaN                   NaN   \n",
              "6                               4             NaN                   NaN   \n",
              "7                               5             NaN                   NaN   \n",
              "8                               3             NaN                   NaN   \n",
              "9                               4             NaN                   NaN   \n",
              "10                              5             NaN                   NaN   \n",
              "11                            NaN               5                    l1   \n",
              "12                            NaN               5                    l2   \n",
              "13                            NaN               5            elasticnet   \n",
              "14                            NaN               6                    l1   \n",
              "15                            NaN               6                    l2   \n",
              "16                            NaN               6            elasticnet   \n",
              "17                            NaN               7                    l1   \n",
              "18                            NaN               7                    l2   \n",
              "19                            NaN               7            elasticnet   \n",
              "20                            NaN               8                    l1   \n",
              "21                            NaN               8                    l2   \n",
              "22                            NaN               8            elasticnet   \n",
              "23                            NaN               9                    l1   \n",
              "24                            NaN               9                    l2   \n",
              "25                            NaN               9            elasticnet   \n",
              "26                            NaN              10                    l1   \n",
              "27                            NaN              10                    l2   \n",
              "28                            NaN              10            elasticnet   \n",
              "29                            NaN              11                    l1   \n",
              "30                            NaN              11                    l2   \n",
              "31                            NaN              11            elasticnet   \n",
              "32                            NaN              12                    l1   \n",
              "33                            NaN              12                    l2   \n",
              "34                            NaN              12            elasticnet   \n",
              "35                            NaN              13                    l1   \n",
              "36                            NaN              13                    l2   \n",
              "37                            NaN              13            elasticnet   \n",
              "38                            NaN              14                    l1   \n",
              "39                            NaN              14                    l2   \n",
              "40                            NaN              14            elasticnet   \n",
              "41                            NaN             NaN                   NaN   \n",
              "\n",
              "    mean_test_score  rank_test_score  \n",
              "0          0.691579               11  \n",
              "1          0.679340               12  \n",
              "2          0.427721               22  \n",
              "3          0.427966               21  \n",
              "4          0.428153               20  \n",
              "5          0.472220               18  \n",
              "6          0.472283               17  \n",
              "7          0.473542               16  \n",
              "8          0.502856               13  \n",
              "9          0.502666               15  \n",
              "10         0.502795               14  \n",
              "11              NaN               31  \n",
              "12         0.771975               10  \n",
              "13              NaN               33  \n",
              "14              NaN               36  \n",
              "15         0.774493                9  \n",
              "16              NaN               39  \n",
              "17              NaN               30  \n",
              "18         0.776877                8  \n",
              "19              NaN               23  \n",
              "20              NaN               42  \n",
              "21         0.777646                7  \n",
              "22              NaN               38  \n",
              "23              NaN               37  \n",
              "24         0.779662                5  \n",
              "25              NaN               35  \n",
              "26              NaN               34  \n",
              "27         0.779659                6  \n",
              "28              NaN               32  \n",
              "29              NaN               41  \n",
              "30         0.780609                4  \n",
              "31              NaN               29  \n",
              "32              NaN               28  \n",
              "33         0.780761                3  \n",
              "34              NaN               27  \n",
              "35              NaN               26  \n",
              "36         0.781292                1  \n",
              "37              NaN               25  \n",
              "38              NaN               24  \n",
              "39         0.781221                2  \n",
              "40              NaN               40  \n",
              "41         0.452959               19  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = pd.DataFrame(grid_search.cv_results_)\n",
        "res = res.drop (['std_fit_time','mean_score_time',\n",
        "                 'std_score_time','params','split0_test_score','split1_test_score',\n",
        "                 'split2_test_score','std_test_score'], axis=1)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7rUfct9PWIk",
        "outputId": "3599b3ea-4b17-4f6d-eaa0-36fd0ac6d99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best model and its parameters:\n",
            "\n",
            " Pipeline(steps=[('vect', TfidfVectorizer()),\n",
            "                ('models', LogisticRegression(C=13, random_state=12345))])\n",
            "The metric of the best model on cross-validation: 0.7812920327938802\n"
          ]
        }
      ],
      "source": [
        "print('The best model and its parameters:\\n\\n', grid_search.best_estimator_)\n",
        "print ('The metric of the best model on cross-validation:', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmh42WyrPWIl",
        "outputId": "aeaf2033-948e-4f9d-c501-8fc22441b66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 on test set is: 0.7850360370666971\n"
          ]
        }
      ],
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "y_pred_test = grid_search.best_estimator_.predict(X_test)\n",
        "f1_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print (\"F1 on test set is:\", f1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyiKU0UaPWIl"
      },
      "source": [
        "Лучшая модель, выбранная при кросс-валидации - логистическая регрессия с параметром регуляризации capacity =13, регуляризацией l2, значение метрики F1 на кросс-валидации 78.1%, на тестовой выбоке  78,5% (удлвлетворяют требованиям проекта)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgIhJuFVPWIl"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDFUmhZpPWIl"
      },
      "source": [
        "Согласно цели проекта - обучить модель выявлять токсичные комментарии на сайте магазина была проведена загрузка необходимых библиотек, датасета, проведена первичная оценка данных.\n",
        "\n",
        "На втором этапе проведена проведена подготовка текстов комментариев к обучению моделей -  удалены лишние символы, пробелы,  проведена токенизация и лемматизация текста.  \n",
        "\n",
        "Лемматизированный текст передан пайплайну, включающему векторайзер TF-IDF, 3 модели (логистическая регрессия, дерево решений, метод ближайших соседей).\n",
        "\n",
        "Проведена кросс-валидация для подбора лучшей модели и ее гиперпараметров, лучшей моделью выбрана логистическая регрессия, метрика F1 на кросс-валидации 78,1%. Получены предсказания на тествой выборке, метрика F1 на тествовой выборке составила 78,5%.\n",
        "\n",
        "Таким образом, логистическая регрессия с учетом ее быстрой работы и удовлетворительного качества предсказаний может быть использована для отбора токсичных комментариев."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1tyIH0bPWIm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 4740,
        "start_time": "2024-03-27T17:46:29.445Z"
      },
      {
        "duration": 894,
        "start_time": "2024-03-27T17:47:35.488Z"
      },
      {
        "duration": 32,
        "start_time": "2024-03-27T17:51:26.743Z"
      },
      {
        "duration": 236,
        "start_time": "2024-03-27T17:52:10.798Z"
      },
      {
        "duration": 32,
        "start_time": "2024-03-27T17:52:28.839Z"
      },
      {
        "duration": 28,
        "start_time": "2024-03-27T17:52:36.992Z"
      },
      {
        "duration": 2362,
        "start_time": "2024-03-27T17:54:23.527Z"
      },
      {
        "duration": 119,
        "start_time": "2024-03-27T17:55:03.015Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T17:55:08.672Z"
      },
      {
        "duration": 952,
        "start_time": "2024-03-27T17:55:14.359Z"
      },
      {
        "duration": 842,
        "start_time": "2024-03-27T17:55:19.711Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T17:57:39.712Z"
      },
      {
        "duration": 10944,
        "start_time": "2024-03-27T17:58:58.808Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T18:00:37.280Z"
      },
      {
        "duration": 18,
        "start_time": "2024-03-27T18:35:38.966Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-27T18:36:04.486Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-27T18:36:41.709Z"
      },
      {
        "duration": 131,
        "start_time": "2024-03-27T18:38:24.758Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T19:27:41.674Z"
      },
      {
        "duration": 912,
        "start_time": "2024-03-27T19:27:42.615Z"
      },
      {
        "duration": 10,
        "start_time": "2024-03-27T19:27:44.383Z"
      },
      {
        "duration": 24,
        "start_time": "2024-03-27T19:29:17.058Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-27T19:29:38.713Z"
      },
      {
        "duration": 18664,
        "start_time": "2024-03-27T19:29:43.674Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-27T19:30:02.340Z"
      },
      {
        "duration": 8443,
        "start_time": "2024-03-27T19:35:39.619Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-27T19:35:48.064Z"
      },
      {
        "duration": 10,
        "start_time": "2024-03-27T19:37:22.099Z"
      },
      {
        "duration": 226,
        "start_time": "2024-03-27T19:40:21.135Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T19:41:07.832Z"
      },
      {
        "duration": 98,
        "start_time": "2024-03-27T19:42:57.621Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-27T19:43:18.157Z"
      },
      {
        "duration": 12,
        "start_time": "2024-03-27T19:50:51.552Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T19:51:35.896Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T19:51:42.380Z"
      },
      {
        "duration": 103783,
        "start_time": "2024-03-27T19:51:52.393Z"
      },
      {
        "duration": 106602,
        "start_time": "2024-03-27T19:53:43.457Z"
      },
      {
        "duration": 10,
        "start_time": "2024-03-27T19:55:35.425Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-27T19:57:45.121Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-27T20:00:26.162Z"
      },
      {
        "duration": 26,
        "start_time": "2024-03-27T20:00:27.074Z"
      },
      {
        "duration": 1508,
        "start_time": "2024-03-27T20:04:00.796Z"
      },
      {
        "duration": 3479,
        "start_time": "2024-03-27T20:04:02.306Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-27T20:04:05.786Z"
      },
      {
        "duration": 49,
        "start_time": "2024-03-27T20:04:05.802Z"
      },
      {
        "duration": 229,
        "start_time": "2024-03-27T20:04:05.853Z"
      },
      {
        "duration": 27,
        "start_time": "2024-03-27T20:04:06.084Z"
      },
      {
        "duration": 2308,
        "start_time": "2024-03-27T20:04:06.113Z"
      },
      {
        "duration": 106866,
        "start_time": "2024-03-27T20:04:08.423Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-27T20:05:55.291Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-27T20:05:55.301Z"
      },
      {
        "duration": 30,
        "start_time": "2024-03-27T20:05:55.308Z"
      },
      {
        "duration": 1443,
        "start_time": "2024-03-28T04:26:24.311Z"
      },
      {
        "duration": 3421,
        "start_time": "2024-03-28T04:26:25.756Z"
      },
      {
        "duration": 14,
        "start_time": "2024-03-28T04:26:29.180Z"
      },
      {
        "duration": 32,
        "start_time": "2024-03-28T04:26:29.196Z"
      },
      {
        "duration": 253,
        "start_time": "2024-03-28T04:26:29.230Z"
      },
      {
        "duration": 25,
        "start_time": "2024-03-28T04:26:29.485Z"
      },
      {
        "duration": 97380,
        "start_time": "2024-03-28T04:26:29.511Z"
      },
      {
        "duration": 7,
        "start_time": "2024-03-28T04:28:06.893Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-28T04:28:06.901Z"
      },
      {
        "duration": 35,
        "start_time": "2024-03-28T04:28:06.917Z"
      },
      {
        "duration": 1388,
        "start_time": "2024-03-28T04:41:21.131Z"
      },
      {
        "duration": 3420,
        "start_time": "2024-03-28T04:41:22.521Z"
      },
      {
        "duration": 14,
        "start_time": "2024-03-28T04:41:25.944Z"
      },
      {
        "duration": 32,
        "start_time": "2024-03-28T04:41:25.960Z"
      },
      {
        "duration": 232,
        "start_time": "2024-03-28T04:41:25.994Z"
      },
      {
        "duration": 25,
        "start_time": "2024-03-28T04:41:26.228Z"
      },
      {
        "duration": 102327,
        "start_time": "2024-03-28T04:41:26.254Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-28T04:43:08.582Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T04:43:08.591Z"
      },
      {
        "duration": 33,
        "start_time": "2024-03-28T04:43:08.598Z"
      },
      {
        "duration": 2,
        "start_time": "2024-03-28T04:43:08.633Z"
      },
      {
        "duration": 14401,
        "start_time": "2024-03-28T04:43:08.636Z"
      },
      {
        "duration": 140,
        "start_time": "2024-03-28T04:43:23.040Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.181Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.187Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.188Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.189Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.190Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.191Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.192Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T04:43:23.193Z"
      },
      {
        "duration": 13805,
        "start_time": "2024-03-28T05:01:56.645Z"
      },
      {
        "duration": 13,
        "start_time": "2024-03-28T05:02:13.212Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:06:17.285Z"
      },
      {
        "duration": 10,
        "start_time": "2024-03-28T05:07:12.958Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T05:11:01.151Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T05:11:17.991Z"
      },
      {
        "duration": 4124,
        "start_time": "2024-03-28T05:13:33.840Z"
      },
      {
        "duration": 9,
        "start_time": "2024-03-28T05:13:39.314Z"
      },
      {
        "duration": 13,
        "start_time": "2024-03-28T05:13:46.759Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:20:45.801Z"
      },
      {
        "duration": 29,
        "start_time": "2024-03-28T05:20:47.082Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T05:20:48.512Z"
      },
      {
        "duration": 31,
        "start_time": "2024-03-28T05:22:15.970Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:22:21.410Z"
      },
      {
        "duration": 30,
        "start_time": "2024-03-28T05:22:22.650Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T05:22:23.778Z"
      },
      {
        "duration": 4079,
        "start_time": "2024-03-28T05:22:26.339Z"
      },
      {
        "duration": 1524,
        "start_time": "2024-03-28T05:22:30.420Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:22:32.170Z"
      },
      {
        "duration": 10,
        "start_time": "2024-03-28T05:22:39.668Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:23:00.541Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:23:03.923Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:23:07.499Z"
      },
      {
        "duration": 2023,
        "start_time": "2024-03-28T05:23:10.850Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:24:06.834Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:24:08.011Z"
      },
      {
        "duration": 2104,
        "start_time": "2024-03-28T05:24:08.827Z"
      },
      {
        "duration": 12,
        "start_time": "2024-03-28T05:26:10.196Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:26:28.435Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:26:33.844Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:26:35.395Z"
      },
      {
        "duration": 2231,
        "start_time": "2024-03-28T05:26:36.564Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:27:20.587Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:27:21.430Z"
      },
      {
        "duration": 2117,
        "start_time": "2024-03-28T05:27:22.007Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:29:03.051Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:29:03.740Z"
      },
      {
        "duration": 2224,
        "start_time": "2024-03-28T05:29:04.317Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:29:37.044Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:29:37.876Z"
      },
      {
        "duration": 3429,
        "start_time": "2024-03-28T05:29:38.403Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:30:33.853Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:30:34.591Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:30:35.591Z"
      },
      {
        "duration": 3517,
        "start_time": "2024-03-28T05:30:36.402Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:31:21.924Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T05:31:22.637Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T05:31:36.155Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:31:37.417Z"
      },
      {
        "duration": 3565,
        "start_time": "2024-03-28T05:31:38.198Z"
      },
      {
        "duration": 1381,
        "start_time": "2024-03-28T05:43:40.143Z"
      },
      {
        "duration": 1002,
        "start_time": "2024-03-28T05:43:41.526Z"
      },
      {
        "duration": 2,
        "start_time": "2024-03-28T05:43:42.529Z"
      },
      {
        "duration": 19,
        "start_time": "2024-03-28T05:43:42.533Z"
      },
      {
        "duration": 41,
        "start_time": "2024-03-28T05:43:42.553Z"
      },
      {
        "duration": 242,
        "start_time": "2024-03-28T05:43:42.595Z"
      },
      {
        "duration": 28,
        "start_time": "2024-03-28T05:43:42.838Z"
      },
      {
        "duration": 104219,
        "start_time": "2024-03-28T05:43:42.868Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-28T05:45:27.088Z"
      },
      {
        "duration": 7,
        "start_time": "2024-03-28T05:45:27.098Z"
      },
      {
        "duration": 38,
        "start_time": "2024-03-28T05:45:27.106Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T05:45:27.145Z"
      },
      {
        "duration": 3921,
        "start_time": "2024-03-28T05:45:27.151Z"
      },
      {
        "duration": 1408,
        "start_time": "2024-03-28T05:45:31.073Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T05:45:32.483Z"
      },
      {
        "duration": 49,
        "start_time": "2024-03-28T05:45:32.490Z"
      },
      {
        "duration": 7,
        "start_time": "2024-03-28T05:45:32.541Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T05:45:32.550Z"
      },
      {
        "duration": 1519,
        "start_time": "2024-03-28T06:58:25.983Z"
      },
      {
        "duration": 1023,
        "start_time": "2024-03-28T06:58:27.503Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T06:58:28.527Z"
      },
      {
        "duration": 45,
        "start_time": "2024-03-28T06:58:28.531Z"
      },
      {
        "duration": 52,
        "start_time": "2024-03-28T06:58:28.578Z"
      },
      {
        "duration": 244,
        "start_time": "2024-03-28T06:58:28.631Z"
      },
      {
        "duration": 27,
        "start_time": "2024-03-28T06:58:28.876Z"
      },
      {
        "duration": 104438,
        "start_time": "2024-03-28T06:58:28.904Z"
      },
      {
        "duration": 12,
        "start_time": "2024-03-28T07:00:13.345Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T07:00:13.359Z"
      },
      {
        "duration": 51,
        "start_time": "2024-03-28T07:00:13.366Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T07:00:13.418Z"
      },
      {
        "duration": 3834,
        "start_time": "2024-03-28T07:00:13.425Z"
      },
      {
        "duration": 1427,
        "start_time": "2024-03-28T07:00:17.261Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T07:00:18.689Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-28T07:00:18.694Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T07:00:18.711Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T07:00:18.718Z"
      },
      {
        "duration": 851420,
        "start_time": "2024-03-28T07:00:18.726Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T07:14:30.147Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T07:14:30.149Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-28T07:14:30.149Z"
      },
      {
        "duration": 11,
        "start_time": "2024-03-28T07:15:12.831Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T07:15:27.855Z"
      },
      {
        "duration": 11,
        "start_time": "2024-03-28T07:19:39.162Z"
      },
      {
        "duration": 55,
        "start_time": "2024-03-28T07:19:46.456Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-28T07:20:47.458Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-28T07:21:46.252Z"
      },
      {
        "duration": 85,
        "start_time": "2024-03-28T07:23:14.158Z"
      },
      {
        "duration": 17,
        "start_time": "2024-03-28T17:07:47.510Z"
      },
      {
        "duration": 9,
        "start_time": "2024-03-28T17:09:02.235Z"
      },
      {
        "duration": 20,
        "start_time": "2024-03-28T17:09:20.003Z"
      },
      {
        "duration": 34,
        "start_time": "2024-03-28T17:09:48.643Z"
      },
      {
        "duration": 107565,
        "start_time": "2024-03-28T17:10:00.773Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T17:13:47.616Z"
      },
      {
        "duration": 34013,
        "start_time": "2024-03-28T17:15:07.541Z"
      },
      {
        "duration": 9,
        "start_time": "2024-03-28T17:15:48.405Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T17:15:54.662Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-28T17:15:55.753Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T17:15:57.117Z"
      },
      {
        "duration": 1224,
        "start_time": "2024-03-28T17:16:00.869Z"
      },
      {
        "duration": 436,
        "start_time": "2024-03-28T17:16:02.909Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T17:16:04.133Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T17:16:07.326Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T17:17:50.495Z"
      },
      {
        "duration": 13,
        "start_time": "2024-03-28T17:21:13.373Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T17:21:24.607Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T17:21:32.805Z"
      },
      {
        "duration": 89591,
        "start_time": "2024-03-28T17:21:37.433Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T17:23:30.488Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T17:23:31.418Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T17:23:32.474Z"
      },
      {
        "duration": 399182,
        "start_time": "2024-03-28T17:23:33.706Z"
      },
      {
        "duration": 18,
        "start_time": "2024-03-28T17:30:36.752Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-28T17:30:44.571Z"
      },
      {
        "duration": 17,
        "start_time": "2024-03-28T17:30:58.307Z"
      },
      {
        "duration": 13,
        "start_time": "2024-03-28T17:31:49.770Z"
      },
      {
        "duration": 21,
        "start_time": "2024-03-28T17:33:23.861Z"
      },
      {
        "duration": 24,
        "start_time": "2024-03-28T17:34:52.897Z"
      },
      {
        "duration": 1377,
        "start_time": "2024-03-28T18:20:04.154Z"
      },
      {
        "duration": 953,
        "start_time": "2024-03-28T18:20:05.533Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T18:20:06.487Z"
      },
      {
        "duration": 19,
        "start_time": "2024-03-28T18:20:06.492Z"
      },
      {
        "duration": 30,
        "start_time": "2024-03-28T18:20:06.513Z"
      },
      {
        "duration": 247,
        "start_time": "2024-03-28T18:20:06.545Z"
      },
      {
        "duration": 27,
        "start_time": "2024-03-28T18:20:06.794Z"
      },
      {
        "duration": 7,
        "start_time": "2024-03-28T18:20:06.823Z"
      },
      {
        "duration": 16,
        "start_time": "2024-03-28T18:20:06.831Z"
      },
      {
        "duration": 38,
        "start_time": "2024-03-28T18:20:06.849Z"
      },
      {
        "duration": 12,
        "start_time": "2024-03-28T18:20:06.889Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T18:20:06.903Z"
      },
      {
        "duration": 16,
        "start_time": "2024-03-28T18:20:06.911Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-28T18:20:06.930Z"
      },
      {
        "duration": 34627,
        "start_time": "2024-03-28T18:20:06.937Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-28T18:20:41.566Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-28T18:20:41.575Z"
      },
      {
        "duration": 23,
        "start_time": "2024-03-28T18:20:41.586Z"
      },
      {
        "duration": 1186,
        "start_time": "2024-03-28T18:20:41.611Z"
      },
      {
        "duration": 431,
        "start_time": "2024-03-28T18:20:42.798Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-28T18:20:43.231Z"
      },
      {
        "duration": 9,
        "start_time": "2024-03-28T18:20:43.236Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-28T18:20:43.247Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-28T18:20:43.256Z"
      },
      {
        "duration": 419725,
        "start_time": "2024-03-28T18:20:43.263Z"
      },
      {
        "duration": 18,
        "start_time": "2024-03-28T18:27:42.990Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-28T18:27:43.010Z"
      },
      {
        "duration": 13,
        "start_time": "2024-03-28T18:27:43.027Z"
      },
      {
        "duration": 2780,
        "start_time": "2024-03-29T17:12:02.708Z"
      },
      {
        "duration": 2426,
        "start_time": "2024-03-29T17:12:21.228Z"
      },
      {
        "duration": 3837,
        "start_time": "2024-03-29T17:12:56.957Z"
      },
      {
        "duration": 3386,
        "start_time": "2024-03-29T17:13:00.796Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T17:13:04.884Z"
      },
      {
        "duration": 16,
        "start_time": "2024-03-29T17:13:05.933Z"
      },
      {
        "duration": 30,
        "start_time": "2024-03-29T17:13:09.564Z"
      },
      {
        "duration": 253,
        "start_time": "2024-03-29T17:13:11.255Z"
      },
      {
        "duration": 24,
        "start_time": "2024-03-29T17:13:12.597Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-29T17:13:16.117Z"
      },
      {
        "duration": 1015683,
        "start_time": "2024-03-29T17:15:35.021Z"
      },
      {
        "duration": 77,
        "start_time": "2024-03-29T17:32:30.706Z"
      },
      {
        "duration": 998409,
        "start_time": "2024-03-29T17:32:39.170Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-29T17:49:17.581Z"
      },
      {
        "duration": 9,
        "start_time": "2024-03-29T17:49:47.558Z"
      },
      {
        "duration": 283,
        "start_time": "2024-03-29T17:54:44.418Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T17:54:50.904Z"
      },
      {
        "duration": 65,
        "start_time": "2024-03-29T17:54:56.896Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T17:55:19.361Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-29T17:55:21.960Z"
      },
      {
        "duration": 83,
        "start_time": "2024-03-29T17:55:51.915Z"
      },
      {
        "duration": 5,
        "start_time": "2024-03-29T18:00:51.997Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-29T18:04:05.495Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T18:04:16.446Z"
      },
      {
        "duration": 15,
        "start_time": "2024-03-29T18:04:21.745Z"
      },
      {
        "duration": 4674,
        "start_time": "2024-03-29T18:04:34.407Z"
      },
      {
        "duration": 1013317,
        "start_time": "2024-03-29T18:22:18.393Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-29T18:39:15.138Z"
      },
      {
        "duration": 2,
        "start_time": "2024-03-29T18:39:20.763Z"
      },
      {
        "duration": 164,
        "start_time": "2024-03-29T18:39:21.817Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T18:39:27.110Z"
      },
      {
        "duration": 4,
        "start_time": "2024-03-29T18:39:28.098Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T18:39:28.938Z"
      },
      {
        "duration": 2469,
        "start_time": "2024-03-29T19:25:11.904Z"
      },
      {
        "duration": 3553,
        "start_time": "2024-03-29T19:25:14.376Z"
      },
      {
        "duration": 850,
        "start_time": "2024-03-29T19:25:17.931Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T19:25:18.782Z"
      },
      {
        "duration": 27,
        "start_time": "2024-03-29T19:25:18.787Z"
      },
      {
        "duration": 33,
        "start_time": "2024-03-29T19:25:18.815Z"
      },
      {
        "duration": 226,
        "start_time": "2024-03-29T19:25:18.849Z"
      },
      {
        "duration": 29,
        "start_time": "2024-03-29T19:25:19.076Z"
      },
      {
        "duration": 27,
        "start_time": "2024-03-29T19:25:19.106Z"
      },
      {
        "duration": 985160,
        "start_time": "2024-03-29T19:25:19.134Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-29T19:41:44.295Z"
      },
      {
        "duration": 9,
        "start_time": "2024-03-29T19:41:44.304Z"
      },
      {
        "duration": 67,
        "start_time": "2024-03-29T19:41:44.314Z"
      },
      {
        "duration": 3,
        "start_time": "2024-03-29T19:41:44.383Z"
      },
      {
        "duration": 8,
        "start_time": "2024-03-29T19:41:44.387Z"
      },
      {
        "duration": 11,
        "start_time": "2024-03-29T19:41:44.396Z"
      },
      {
        "duration": 4591898,
        "start_time": "2024-03-29T19:41:44.408Z"
      },
      {
        "duration": 362,
        "start_time": "2024-03-29T20:58:16.308Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-29T20:58:16.672Z"
      },
      {
        "duration": 0,
        "start_time": "2024-03-29T20:58:16.673Z"
      },
      {
        "duration": 33,
        "start_time": "2024-03-30T03:46:23.078Z"
      },
      {
        "duration": 6,
        "start_time": "2024-03-30T03:46:32.310Z"
      },
      {
        "duration": 20,
        "start_time": "2024-03-30T03:46:42.853Z"
      },
      {
        "duration": 2043,
        "start_time": "2024-03-30T03:46:56.869Z"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "247px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}